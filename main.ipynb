{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot\n",
    "from optparse import OptionParser\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calclaim (cost,dmg,loc,sev):\n",
    "  if(dmg==0 and sev==0):\n",
    "    return 0.25\n",
    "  cnt = 1\n",
    "  if(loc == 1 ):\n",
    "    cnt *= 2\n",
    "  else:\n",
    "    cnt *= 3\n",
    "\n",
    "  if (sev == 0):\n",
    "    cnt *= 0.5\n",
    "  elif(sev==1):\n",
    "    cnt *= 3\n",
    "  else:\n",
    "    cnt *= 7\n",
    "\n",
    "  if (cost==0):\n",
    "    cnt *= 1\n",
    "  elif(cost==1):\n",
    "    cnt *= 1.5\n",
    "  else:\n",
    "    cnt *= 4\n",
    "  \n",
    "  return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(picture):\n",
    "    res= Image.new(picture.mode, picture.size)\n",
    "    width, height = picture.size\n",
    "\n",
    "    for i in range(0, width):\n",
    "        for j in range(0, height):\n",
    "            pixel=picture.getpixel((i,j))\n",
    "            avg=int((pixel[0]+pixel[1]+pixel[2])/3)\n",
    "            res.putpixel((i,j),(avg,avg,avg))\n",
    "    res.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(picture):\n",
    "    width, height = picture.size\n",
    "    normalized_array = []\n",
    "    for j in range(0, height):\n",
    "\t    for i in range(0, width):\n",
    "\t\t    pixel = picture.getpixel((i,j))\n",
    "\t\t    normalized_array.append( pixel[0] / 255.0 )\n",
    "    return np.array(normalized_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIsDamaged():\n",
    "  image_size = 150\n",
    "  #Load the VGG model\n",
    "  vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "  # Freeze the layers except the last 4 layers\n",
    "  for layer in vgg_conv.layers[:-4]:\n",
    "      layer.trainable = False\n",
    "\n",
    "  # Create the model\n",
    "  model = models.Sequential()\n",
    "  \n",
    "  # Add the vgg convolutional base model\n",
    "  model.add(vgg_conv)\n",
    "  \n",
    "  # Add new layers\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1024, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "  \n",
    "  # Show a summary of the model. Check the number of trainable parameters\n",
    "  model.summary()\n",
    "\n",
    "  model.load_weights('/content/drive/My Drive/dataset_zapsure/dmgornot_weights.h5')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDamaged(imgpath,model):\n",
    "  image_size = 150 \n",
    "  img = Image.open(imgpath).resize((image_size,image_size))\n",
    "  img_arr = np.expand_dims(img_to_array(img), axis=0)\n",
    "\n",
    "  image = preprocess_input(img_arr)\n",
    "  prediction = model.predict(image)\n",
    "\n",
    "  maxval = prediction.max()\n",
    "  if(maxval == prediction[0][0]):\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDmgLoc():\n",
    "  image_size = 150\n",
    "  #Load the VGG model\n",
    "  vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "  # Freeze the layers except the last 4 layers\n",
    "  for layer in vgg_conv.layers[:-4]:\n",
    "      layer.trainable = False\n",
    "\n",
    "  # Create the model\n",
    "  model = models.Sequential()\n",
    "  \n",
    "  # Add the vgg convolutional base model\n",
    "  model.add(vgg_conv)\n",
    "  \n",
    "  # Add new layers\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1024, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(3, activation='softmax'))\n",
    "  \n",
    "  # Show a summary of the model. Check the number of trainable parameters\n",
    "  model.summary()\n",
    "\n",
    "  model.load_weights('/content/drive/My Drive/dataset_zapsure/dmgloc_weights.h5')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmgLoc(imgpath,model):\n",
    "  image_size = 150\n",
    "  img = Image.open(imgpath).resize((image_size,image_size))\n",
    "  img_arr = np.expand_dims(img_to_array(img), axis=0)\n",
    "\n",
    "  image = preprocess_input(img_arr)\n",
    "  prediction = model.predict(image)\n",
    "\n",
    "  maxval = prediction.max()\n",
    "  if(maxval == prediction[0][0]):\n",
    "    return 0 #bonnett\n",
    "  elif(maxval == prediction[0][1]):\n",
    "    return 1 #rear\n",
    "  else:\n",
    "    return 2 #sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDmgSev():\n",
    "  image_size = 150\n",
    "  #Load the VGG model\n",
    "  vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "  # Freeze the layers except the last 4 layers\n",
    "  for layer in vgg_conv.layers[:-4]:\n",
    "      layer.trainable = False\n",
    "\n",
    "  # Create the model\n",
    "  model = models.Sequential()\n",
    "  \n",
    "  # Add the vgg convolutional base model\n",
    "  model.add(vgg_conv)\n",
    "  \n",
    "  # Add new layers\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1024, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(3, activation='softmax'))\n",
    "  \n",
    "  # Show a summary of the model. Check the number of trainable parameters\n",
    "  model.summary()\n",
    "\n",
    "  model.load_weights('/content/drive/My Drive/dataset_zapsure/dmgsev_weights.h5')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmgSev(imgpath,model):\n",
    "  image_size = 150\n",
    "  img = Image.open(imgpath).resize((image_size,image_size))\n",
    "  img_arr = np.expand_dims(img_to_array(img), axis=0)\n",
    "\n",
    "  image = preprocess_input(img_arr)\n",
    "  prediction = model.predict(image)\n",
    "\n",
    "  maxval = prediction.max()\n",
    "  if(maxval == prediction[0][0]):\n",
    "    return 0\n",
    "  elif(maxval == prediction[0][1]):\n",
    "    return 1\n",
    "  else:\n",
    "    return 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",

   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
